{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python mediapipe msvc-runtime\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "import time\n",
    "import ast\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from google.protobuf.internal.containers import RepeatedCompositeFieldContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_to_write = './results/data_pose_video.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grabbing the Holistic Model from Mediapipe and\n",
    "# # Initializing the Model\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# holistic_model = mp_holistic.Holistic(\n",
    "# \tmin_detection_confidence=0.75,\n",
    "# \tmin_tracking_confidence=0.5\n",
    "# )\n",
    "\n",
    "\n",
    "# # Initializing the drawing utils for drawing the facial landmarks on image\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# drawing_spec_lines_r = mp_drawing.DrawingSpec(  # линии соединения\n",
    "#           color=(255,0,0),\n",
    "#           thickness=2,\n",
    "#           circle_radius=1\n",
    "#         )\n",
    "\n",
    "# drawing_spec_lines_l = mp_drawing.DrawingSpec(  # линии соединения\n",
    "#           color=(0,255,0),\n",
    "#           thickness=2,\n",
    "#           circle_radius=1\n",
    "#         )\n",
    "\n",
    "\n",
    "# image = cv2.imread(r\"C:\\Users\\ivano\\Desktop\\SBER\\demo2.jpg\")\n",
    "\n",
    "# # Converting the from BGR to RGB\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Making predictions using holistic model\n",
    "# # To improve performance, optionally mark the image as not writeable to\n",
    "# # pass by reference.\n",
    "# image.flags.writeable = False\n",
    "# results = holistic_model.process(image)\n",
    "# image.flags.writeable = True\n",
    "\n",
    "# # # Create a black image\n",
    "# image = np.zeros(image.shape, np.uint8) \n",
    "# image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# # Drawing the Facial Landmarks\n",
    "# mp_drawing.draw_landmarks(\n",
    "#   image,\n",
    "#   results.face_landmarks,\n",
    "#   mp_holistic.FACEMESH_CONTOURS,\n",
    "#   mp_drawing.DrawingSpec(\n",
    "#     color=(255,0,255),\n",
    "#     thickness=1,\n",
    "#     circle_radius=1\n",
    "#   ),\n",
    "#   mp_drawing.DrawingSpec(\n",
    "#     color=(0,255,255),\n",
    "#     thickness=1,\n",
    "#     circle_radius=1\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# # Drawing Right hand Land Marks\n",
    "# mp_drawing.draw_landmarks(\n",
    "#   image, \n",
    "#   results.right_hand_landmarks, \n",
    "#   mp_holistic.HAND_CONNECTIONS,\n",
    "#   connection_drawing_spec=drawing_spec_lines_r\n",
    "# )\n",
    "\n",
    "# # Drawing Left hand Land Marks\n",
    "# mp_drawing.draw_landmarks(\n",
    "#   image, \n",
    "#   results.left_hand_landmarks, \n",
    "#   mp_holistic.HAND_CONNECTIONS,\n",
    "#   connection_drawing_spec=drawing_spec_lines_l\n",
    "# )\n",
    "\n",
    "# # Drawing pose Marks\n",
    "# mp_drawing.draw_landmarks(\n",
    "#   image, \n",
    "#   results.pose_landmarks, \n",
    "#   mp_holistic.POSE_CONNECTIONS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_fps(current_fps, fps_buffer):\n",
    "    # Добавляем текущее значение в буфер\n",
    "    fps_buffer.pop(0)\n",
    "    fps_buffer.append(current_fps)\n",
    "\n",
    "    # Вычисляем среднее значение в буфере\n",
    "    average_fps = sum(fps_buffer) / len(fps_buffer)\n",
    "\n",
    "    return average_fps, fps_buffer\n",
    "\n",
    "\n",
    "\n",
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "\tmin_detection_confidence=0.75,\n",
    "\tmin_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec_lines_r = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(255,0,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "drawing_spec_lines_l = mp_drawing.DrawingSpec(  # линии соединения\n",
    "          color=(0,255,0),\n",
    "          thickness=2,\n",
    "          circle_radius=1\n",
    "        )\n",
    "\n",
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture('../../../../../Desktop/SBER/slovo/train/00019bad-4c36-4cc5-a940-2f994bc4037a.mp4')\n",
    " \n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "N = 15 # окно усреднения fps\n",
    "fps_buffer = [0] * N  # Инициализация массива предыдущих значений\n",
    " \n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    " \n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    " \n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "     # Create a black image\n",
    "    image = np.zeros(image.shape, np.uint8)\n",
    "\n",
    "    # Drawing the Facial Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.face_landmarks,\n",
    "      mp_holistic.FACEMESH_CONTOURS,\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(255,0,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      ),\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(0,255,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      )\n",
    "    )\n",
    " \n",
    "    # Drawing Right hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.right_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_r\n",
    "    )\n",
    " \n",
    "    # Drawing Left hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.left_hand_landmarks, \n",
    "      mp_holistic.HAND_CONNECTIONS,\n",
    "      connection_drawing_spec=drawing_spec_lines_l\n",
    "    )\n",
    "\n",
    "    # Drawing pose Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image, \n",
    "      results.pose_landmarks, \n",
    "      mp_holistic.POSE_CONNECTIONS\n",
    "    )\n",
    "\n",
    "     \n",
    "    # Calculating the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "\n",
    "    fps, fps_buffer = calculate_average_fps(fps, fps_buffer)\n",
    "     \n",
    "    # Displaying FPS on the image\n",
    "    cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (255,100,0), 2)\n",
    " \n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    " \n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_points_file(landmarks_list=results.pose_landmarks.landmark, file_name=file_path_to_write):\n",
    "    \"\"\"\n",
    "    Записываем результаты в файл для добавления в словарь\n",
    "    \"\"\"\n",
    "    data_to_write = []\n",
    "    for landmark in landmarks_list:\n",
    "        data_to_write.append({\n",
    "            'x': landmark.x,\n",
    "            'y': landmark.y,\n",
    "            'z': landmark.z,\n",
    "            'visibility': landmark.visibility\n",
    "        })\n",
    "\n",
    "    print('Запись файла...')\n",
    "    with open(file_path_to_write, 'w') as file:\n",
    "        file.write(str(data_to_write))\n",
    "    print('Успешно!')\n",
    "\n",
    "    return data_to_write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Адаптируем results к потоку фоток(цикл + размерность+=1) \n",
    "\n",
    "### Дальше этот `results` отдаем на сглаживание изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_points_file(file=file_path_to_write, image=image):\n",
    "    \"\"\"\n",
    "    Чтение точек из файла или объекта для отрисовки\n",
    "    + отрисовка тестовая\n",
    "    На вход: путь или объект\n",
    "    На выход: заисанный объект в переменную\n",
    "    \"\"\"\n",
    "    if type(file) is str:\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        data = ast.literal_eval(content)\n",
    "    else:\n",
    "        data = file\n",
    "\n",
    "\n",
    "    landmark_list = landmark_pb2.NormalizedLandmarkList()\n",
    "\n",
    "    print('Читаем точки..')\n",
    "    for point in data:\n",
    "    # Добвление NormalizedLandmark в NormalizedLandmarkList\n",
    "        landmark = landmark_list.landmark.add()\n",
    "        landmark.x = point['x'] \n",
    "        landmark.y = point['y']\n",
    "        landmark.z = point['z']\n",
    "        landmark.visibility = point['visibility']\n",
    "    print('Точки прочитаны успешно!\\n')\n",
    "    \n",
    "    print('Создание класса визуализации...')\n",
    "    # # Теперь вы можете использовать pose_landmarks с функцией draw_landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, \n",
    "        landmark_list, \n",
    "        mp_holistic.POSE_CONNECTIONS\n",
    "    )\n",
    "    print('Класс создан без ошибок!\\n')\n",
    "\n",
    "    print('Вывод изображения...')\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Работа завершена!')\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запись файла...\n",
      "Успешно!\n",
      "Читаем точки..\n",
      "Точки прочитаны успешно!\n",
      "\n",
      "Создание класса визуализации...\n",
      "Класс создан без ошибок!\n",
      "\n",
      "Вывод изображения...\n",
      "Работа завершена!\n"
     ]
    }
   ],
   "source": [
    "results = record_points_file()\n",
    "image_to_draw = read_points_file(results, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
